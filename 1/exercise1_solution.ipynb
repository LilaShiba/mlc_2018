{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "(1) Create a model whatever you like. It may be $y = 3x_1 + 5x_2 + \\mu$ or $y = 4x_1 - 3x_2 + 9x_3 + \\mu$. Then:\n",
    "    - (a) generate random 30 observations depend on the model.\n",
    "    - (b) fit a linear model depends on the observations generated by step (a), and record the coefficients.\n",
    "    - (c) repeat (a) and (b) 100 times. Calculate the mean and variance of the coefficients.\n",
    "Note that each time the generated observations should come from the sample distribution. If you don not understand, just use the `random.rand` function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1:\n",
    "For example the true model is:\n",
    "$$Y = x_1 + 2x_2 + \\mu$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the estimated coefficients are: [1.01364387 2.01981367]\n",
      "The variance of the estimated coefficients are: [0.0346508  0.03255635]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "coefs = []\n",
    "ols = linear_model.LinearRegression()\n",
    "np.random.seed(100)\n",
    "for i in range(100):\n",
    "    x = np.random.rand(30, 2)\n",
    "    # sliced the array, taking all rows (:) but keeping the ith column (ith)\n",
    "    y = x[:, 0] + 2*x[:, 1] + np.random.rand(30)\n",
    "    ols.fit(x, y)\n",
    "    coefs.append(ols.coef_)\n",
    "\n",
    "print(\"The mean of the estimated coefficients are: \" + str(np.mean(coefs, 0)))\n",
    "print (\"The variance of the estimated coefficients are: \" + str(np.var(coefs, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean of the estimated coefficients is very closed to the true coefficients. And the variance is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(2) This question involves the use of simple linear regression on the Auto data set(In the file \"Auto.csv\"). Perform a simple linear regression with *mpg* as the response and *horsepower* as the predictor. \n",
    "    - (a) What is the coefficient of mpg? How to explain it?\n",
    "    - (b) What is the determination of the model? How to explain it?\n",
    "    - (c) Write down the formula of the model.\n",
    "    - (d) What is the predicted mpg associated with a horsepower of 98?\n",
    "    - (e) Plot the response and the predictor.  as well as the least squares regression line.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15784473]]\n",
      "0.6059482578894348\n",
      "[array([[-0.15784473]]), array([39.93586102])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[98].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9652ebe55dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# (d) prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m98\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# (e)plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    241\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[98].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auto = pd.read_csv('Auto.csv')\n",
    "auto.head()\n",
    "y = auto[['mpg']]\n",
    "x = auto[['horsepower']]\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(x, y)\n",
    "# (a) coefficient\n",
    "print(ols.coef_)\n",
    "\n",
    "# (b) determination\n",
    "print(ols.score(x, y))\n",
    "\n",
    "# (c) formula\n",
    "print([ols.coef_, ols.intercept_])\n",
    "\n",
    "# (d) prediction\n",
    "print(ols.predict([98]))\n",
    "\n",
    "# (e)plot\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as pl\n",
    "pl.scatter(x ,y)\n",
    "pl.plot(x, ols.predict(x), color='red')\n",
    "pl.xlabel('horsepower')\n",
    "pl.ylabel('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (a)The coefficient of variable is -0.1578, say one unit's increasing on horsepower will result in 0.1578 unit's decreasing on mpg.\n",
    "- (b)The determination id 60.1%, 60.1% of the variance of mpg can be explained by the horsepower variable.\n",
    "- (c) The formula of the model is $$\\text{mpg} = -0.1578*\\text{horsepower} + 39.9359$$\n",
    "- (d)  24.4671."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(3) Do not use the sklearn library, calculate the coefficients manually by employing the numpy library, as well as the determination and prediction. Note that the results should be exactly the same with the results in question (2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are: \n",
      "[[ 39.93586102]\n",
      " [ -0.15784473]]\n",
      "\n",
      "The determination is: [[ 0.60594826]]\n",
      "\n",
      "The prediction of horsepower=98 is: [[ 24.46707715]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "auto = pd.read_csv('data/Auto.csv')\n",
    "auto.head()\n",
    "y = auto[['mpg']]\n",
    "x = auto[['horsepower']]\n",
    "\n",
    "import numpy as np\n",
    "x = np.mat(x)\n",
    "x = np.column_stack((np.ones([x.shape[0], 1]), x))\n",
    "y = np.mat(y)\n",
    "## estimatation\n",
    "estimate = (x.T*x).I * x.T * y\n",
    "print \"The coefficients are: \\n\" + str(estimate) + '\\n'\n",
    "\n",
    "## determination\n",
    "prediction = x * estimate\n",
    "deter = (prediction - y.mean()).T * (prediction - y.mean()) / ((y - y.mean()).T * (y - y.mean()))\n",
    "print \"The determination is: \" + str(deter) + '\\n'\n",
    "\n",
    "## prediction\n",
    "pred = np.mat([1, 98]) * estimate\n",
    "print \"The prediction of horsepower=98 is: \" + str(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a linear model on a real data set, and try to explain the model. The step is similar to question (2). The data set may come from arbitrarily subject that you are interested. We are happy to see using machine learning algorithms to deal with various of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
